# -*- coding: utf-8 -*-
"""Sigmoid-Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IPJ_ovcVc8NoTvzMvcx1Dm2hvXtBfbyi
"""

!unzip CLEANed3.zip

pip install aplpy

import aplpy
import matplotlib
gc=aplpy.FITSFigure("CLEANed3.fits")
gc.show_colorscale(cmap=matplotlib.cm.gray_r,vmin=0.0,vmax=0.005)
gc.show_contour(levels=[-0.0005,0.0005,0.001,0.002,0.004,0.008])
gc.add_label(0.2,0.05,'0825+317',relative='axes')
gc.save('0825.png')

!pip install autokeras



from google.colab import drive
drive.mount('/content/drive')

import cv2, glob, os, numpy as np, PIL
#import autokeras as ak
import tensorflow as tf

import imgaug.augmenters as iaa
import imageio
import imgaug as ia
from tqdm import tqdm

!unzip /content/drive/MyDrive/Sigmoid_Classification/data.zip

import tensorflow.keras,os
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D , Flatten
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import numpy as np


train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(
    rotation_range=15,
    width_shift_range=0.1,
    height_shift_range=0.1,
    shear_range=0.1,
    brightness_range=[0.5, 1.25],
    horizontal_flip=True,
    vertical_flip=True,
    preprocessing_function=tf.keras.applications.vgg16.preprocess_input
)

test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(
    preprocessing_function=tf.keras.applications.vgg16.preprocess_input
)
IMG_SIZE= (224,224)
RANDOM_SEED = 1
train_generator = train_datagen.flow_from_directory(
    '/content/Images/training',
    color_mode='rgb',
    target_size=IMG_SIZE,
    batch_size=32,
    class_mode='binary',
    seed=RANDOM_SEED
)


validation_generator = test_datagen.flow_from_directory(
    '/content/Images/validation',
    color_mode='rgb',
    target_size=IMG_SIZE,
    batch_size=16,
    class_mode='binary',
    seed=RANDOM_SEED
)

base_model = tf.keras.applications.VGG16(
    weights="imagenet",
    include_top=False,
    input_shape=IMG_SIZE + (3,)
)

model = tf.keras.models.Sequential()
model.add(base_model)
model.add(tf.keras.layers.Flatten())
model.add(tf.keras.layers.Dropout(0.5))
model.add(tf.keras.layers.Dense(1, activation='sigmoid'))

model.layers[0].trainable = False

model.compile(
    loss='binary_crossentropy',
    optimizer=tf.keras.optimizers.Adam(),
    metrics=['accuracy']
)

model.summary()

EPOCHS = 25
early_stopping = tf.keras.callbacks.EarlyStopping(
    monitor='val_accuracy',
    mode='max',
    patience=6
)

history = model.fit_generator(
    train_generator,
    steps_per_epoch=50,
    epochs=EPOCHS,
    validation_data=validation_generator,
    validation_steps=25,
    callbacks=[early_stopping]
)



model = Sequential()
model.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding="same", activation="relu"))
model.add(Conv2D(filters=64,kernel_size=(3,3),padding="same", activation="relu"))
model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))
model.add(Conv2D(filters=128, kernel_size=(3,3), padding="same", activation="relu"))
model.add(Conv2D(filters=128, kernel_size=(3,3), padding="same", activation="relu"))
model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))
model.add(Conv2D(filters=256, kernel_size=(3,3), padding="same", activation="relu"))
model.add(Conv2D(filters=256, kernel_size=(3,3), padding="same", activation="relu"))
model.add(Conv2D(filters=256, kernel_size=(3,3), padding="same", activation="relu"))
model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))
model.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))
model.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))
model.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))
model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))
model.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))
model.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))
model.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))
model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))
model.add(Flatten())
model.add(Dense(units=4096,activation="relu"))
model.add(Dense(units=4096,activation="relu"))
model.add(Dense(units=2, activation="softmax"))

from tensorflow.keras.optimizers import Adam
import tensorflow.keras as keras
opt = Adam(lr=0.001)
model.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])

from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping
checkpoint = ModelCheckpoint("vgg16_1.h5", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)
early = EarlyStopping(monitor='val_acc', min_delta=0, patience=20, verbose=1, mode='auto')
history = model.fit_generator(
    traindata,
    steps_per_epoch=100,
    epochs=100,
    validation_data=testdata,
    validation_steps=5,
    callbacks=[early])

cme_files = glob.glob(os.path.join('/content/drive/MyDrive/Sigmoid_Classification/v1/cme', '*.png'))
#cme_files = cme_files[:len(sigmoid_files)]
sigmoid_files = glob.glob(os.path.join('/content/drive/MyDrive/Sigmoid_Classification/v1/sigmoid', '*.png'))

c_train = []
for i in cme_files:
  img = cv2.imread(i)
  img = cv2.resize(img, (224,224))
  c_train.append(img)

s_train = []
for i in sigmoid_files:
  img = cv2.imread(i)
  img = cv2.resize(img, (224,224))
  s_train.append(img)

import numpy as np
c_train = np.asarray(c_train)
s_train = np.asarray(s_train)

rot = []
for j in tqdm(range(1,359,45)):
  for i in (range(len(c_train))):
    rotate=iaa.Affine(rotate=(j))
    rotated_image=rotate.augment_image(c_train[i])
    rot.append(rotated_image)
rot = np.asarray(rot)
c_train = np.concatenate([c_train, rot ],axis=0)
c_train.shape

rot = []
for j in tqdm(range(1,359,45)):
  for i in (range(len(s_train))):
    rotate=iaa.Affine(rotate=(j))
    rotated_image=rotate.augment_image(s_train[i])
    rot.append(rotated_image)
rot = np.asarray(rot)
s_train = np.concatenate([s_train, rot ],axis=0)
s_train.shape

train = np.concatenate([c_train, s_train ],axis=0)
train.shape

label_cme = np.zeros(2205)
label_sigmoid = np.ones(2205)
label = np.concatenate((label_cme, label_sigmoid) , axis= 0)
label.shape

from sklearn.model_selection import train_test_split
train = np.array(train)
df = np.array(label)
X_train, X_test,y_train,  y_test = train_test_split(train, df, test_size = 0.1, shuffle= True)

print(X_train.shape, y_train.shape, X_test.shape, y_test.shape )

import tensorflow.keras,os
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D , Flatten
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import numpy as np


model = Sequential()
model.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding="same", activation="relu"))
model.add(Conv2D(filters=64,kernel_size=(3,3),padding="same", activation="relu"))
model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))
model.add(Conv2D(filters=128, kernel_size=(3,3), padding="same", activation="relu"))
model.add(Conv2D(filters=128, kernel_size=(3,3), padding="same", activation="relu"))
model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))
model.add(Conv2D(filters=256, kernel_size=(3,3), padding="same", activation="relu"))
model.add(Conv2D(filters=256, kernel_size=(3,3), padding="same", activation="relu"))
model.add(Conv2D(filters=256, kernel_size=(3,3), padding="same", activation="relu"))
model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))
model.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))
model.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))
model.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))
model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))
model.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))
model.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))
model.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))
model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))
model.add(Flatten())
model.add(Dense(units=4096,activation="relu"))
model.add(Dense(units=4096,activation="relu"))
model.add(Dense(units=1, activation="sigmoid"))

from tensorflow.keras.optimizers import Adam
import tensorflow.keras as keras
opt = Adam(learning_rate=0.001)
model.compile(optimizer=opt, loss=keras.losses.binary_crossentropy, metrics=['accuracy'])

history = model.fit(X_train,y_train,
    epochs=10, batch_size= 20)

from tensorflow.keras.models import Sequential

from tensorflow.keras.applications import ResNet50
import keras 
from keras.layers import Dense
base_model = ResNet50(include_top=True, input_shape=(224, 224, 3))
model = Sequential()
model.add(base_model)

model.add(Dense(100, activation='sigmoid'))

model.add(Dense(1, activation='sigmoid'))

model.summary()

model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),
              loss=tf.keras.losses.BinaryCrossentropy())

model.fit(x=X_train, y=y_train, batch_size=5, epochs=3, validation_split=0.1, shuffle=True)

model.evaluate(x=X_test, y = y_test)

print(model.predict(
    x = np.expand_dims(X_test[1],axis=0)
))
print(y_train[1])

!pip install autokeras

import autokeras as ak  
# Initialize the image classifier.
#clf = ak.ImageClassifier(overwrite=True,project_name='/content/drive/MyDrive/Sigmoid_Classification/v1/vanilla' , max_trials=1)
clf = ak.ImageClassifier(overwrite=True,project_name='/content/' , max_trials=1)
# Feed the image classifier with training data.
clf.fit(X_train, y_train, epochs=30)

# Predict with the best model.
#predicted_y = clf.predict(np.expand_dims(X_test[1], axis=0))
#print(predicted_y)


# Evaluate the best model with testing data.
print(clf.evaluate(X_test, y_test))

y_test[8]

model = clf.export_model()

print(type(model))  # <class 'tensorflow.python.keras.engine.training.Model'>

try:
    model.save("/content/drive/MyDrive/Sigmoid_Classification/v1/vanilla/export/autokeras", save_format="tf")
except Exception:
    model.save("/content/drive/MyDrive/Sigmoid_Classification/v1/vanilla/export/autokeras.h5")

from tensorflow import load_model
loaded_model = load_model("/content/drive/MyDrive/Sigmoid_Classification/v1/vanilla/export/autokeras", custom_objects=ak.CUSTOM_OBJECTS)

# Commented out IPython magic to ensure Python compatibility.
# clone YOLOv5 repository
!git clone https://github.com/ultralytics/yolov5  # clone repo
# %cd yolov5
!git reset --hard 886f1c03d839575afecb059accf74296fad395b6
!pip install -qr requirements.txt

# Commented out IPython magic to ensure Python compatibility.
# when we ran this, we saw .007 second inference time. That is 140 FPS on a TESLA P100!
# use the best weights!
# %cd /content/drive/MyDrive/Yolo_sigmoid/content/yolov5
!python detect.py --weights /content/drive/MyDrive/Yolo_sigmoid/content/yolov5/runs/train/yolov5s_results/weights/best.pt --img 1024 --conf 0.05 --source /content/drive/MyDrive/Yolo_sigmoid/Data/test/ --save-txt

import cv2
import matplotlib.pyplot as plt
import os, glob

path_img = glob.glob(os.path.join('/content/drive/MyDrive/Yolo_sigmoid/Data/test','*.png'))
path_img.sort()
path_label = glob.glob(os.path.join('/content/drive/MyDrive/Yolo_sigmoid/content/yolov5/runs/detect/exp11/labels','*.txt'))

for i in range(len(path_img)):
  img = cv2.imread(path_img[i])
  dh, dw, _ = img.shape

  fl = open(path_label[i], 'r')
  data = fl.readlines()
  fl.close()
  k = 1
  for dt in data:

      # Split string to float
      _, x, y, w, h = map(float, dt.split(' '))

      # Taken from https://github.com/pjreddie/darknet/blob/810d7f797bdb2f021dbe65d2524c2ff6b8ab5c8b/src/image.c#L283-L291
      # via https://stackoverflow.com/questions/44544471/how-to-get-the-coordinates-of-the-bounding-box-in-yolo-object-detection#comment102178409_44592380
      l = int((x - w / 2) * dw)
      r = int((x + w / 2) * dw)
      t = int((y - h / 2) * dh)
      b = int((y + h / 2) * dh)
      
      if l < 0:
          l = 0
      if r > dw - 1:
          r = dw - 1
      if t < 0:
          t = 0
      if b > dh - 1:
          b = dh - 1

      #cv2.rectangle(img, (l, t), (r, b), (0, 0, 255), 1)
      img1 = img[t:b,l:r]
      cv2.imwrite( '/content/drive/MyDrive/Yolo_sigmoid/Data/test/crop/' +str(i) + str(k) + '.png' , img1 )
      k = k+1

test_files = glob.glob(os.path.join('/content/drive/MyDrive/Yolo_sigmoid/Data/test/crop/', '*.png'))
test = []
for i in test_files:
  img = cv2.imread(i)
  img = cv2.resize(img, (128,128))
  test.append(img)
test = np.asarray(test)
test.shape

cd /content/

pred = clf.predict(np.expand_dims(test[7], axis=0))
print(pred)

test_img = cv2.imread('/content/04.png')
test_img = cv2.resize(test_img, (128,128))
test_img = np.expand_dims(test_img, axis=0)
print(test_img.shape)
pred = clf.predict(test_img)
print(pred)

"""Custom

"""

from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions
from tensorflow.keras.preprocessing.image import ImageDataGenerator

img_height , img_width = (224,224)

train_dir = '/content/drive/MyDrive/Sigmoid_Classification/v2-tf-models/data/train'
valid_dir = '/content/drive/MyDrive/Sigmoid_Classification/v2-tf-models/data/valid'
test_dir =  '/content/drive/MyDrive/Sigmoid_Classification/v2-tf-models/data/test'

import tensorflow as tf

train_datagen = ImageDataGenerator(preprocessing_function= preprocess_input,
    rotation_range=180,
    shear_range=0.2,
    channel_shift_range=0.0,
    fill_mode="nearest",
    horizontal_flip=True,
    vertical_flip=True,
    
)

train_generator = train_datagen.flow_from_directory(train_dir, target_size=(img_height,img_width), batch_size= 4,class_mode='categorical', subset='training' )

valid_generator = train_datagen.flow_from_directory(valid_dir, target_size=(img_height,img_width), batch_size= 1,class_mode='categorical', subset='training' )

test_generator = train_datagen.flow_from_directory(test_dir, target_size=(img_height,img_width), batch_size= 1,class_mode='categorical', subset='training' )

from tensorflow.keras.applications.resnet50 import ResNet50
from tensorflow.keras.models import Model
import keras
from tensorflow.python.framework.ops import disable_eager_execution
disable_eager_execution()
base_model = ResNet50(include_top=False, weights='imagenet')
layer = base_model.output
layer = keras.layers.GlobalAveragePooling2D()(layer)
layer = keras.layers.Dense( 1024, activation = 'relu')(layer)
layer = keras.layers.Dense( 512, activation = 'relu')(layer)
output = keras.layers.Dense(train_generator.num_classes, activation = 'sigmoid')(layer)
#merged_out = tf.keras.layers.concatenate([wide_model.output, deep_model.output])
model = Model(inputs= base_model, outputs = output)
for layer in restnet.layers:
    layer.trainable = False

model.summary()



from tensorflow.keras.applications.resnet50 import ResNet50
from tensorflow.keras.models import Model
import keras
restnet = ResNet50(include_top=False, weights='imagenet', input_shape=(512,512,3))

layer = restnet.layers[-1].output
layer = keras.layers.Conv2D(1024, (2, 2), activation='relu', padding='same')(layer)
layer = keras.layers.MaxPooling2D()(layer)
layer = keras.layers.Conv2D(512, (2, 2), activation='relu', padding='same')(layer)
layer = keras.layers.MaxPooling2D()(layer)
layer = keras.layers.Conv2D(256, (2, 2), activation='relu', padding='same')(layer)
layer = keras.layers.MaxPooling2D()(layer)
layer = keras.layers.Conv2D(128, (2, 2), activation='relu', padding='same')(layer)
output = keras.layers.Flatten()(layer)
#layer = keras.layers.Dense()


#restnet = Model(restnet.input, output)
for layer in restnet.layers:
    layer.trainable = False


restnet.summary()

from tensorflow.keras.applications import ResNet50
from tensorflow.python.keras.models import Sequential
from tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D

base_model = Sequential()
base_model.add(ResNet50(include_top=False, weights='imagenet', pooling='max'))
base_model.add(Dense(1, activation='sigmoid'))

base_model.compile(optimizer = tf.keras.optimizers.SGD(lr=0.0001), loss = 'binary_crossentropy', metrics = ['acc'])

resnet_history = base_model.fit(train_generator, validation_data = valid_generator, steps_per_epoch = 100, epochs = 10)



model = ResNet50(
    include_top=False,
    weights="imagenet",
    input_tensor=None,
    input_shape= (128,128,3),
    pooling=None,
    classes=2
)

model.summary()

model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

model.fit(X_train, y_train, epochs=15, batch_size=10)

