# -*- coding: utf-8 -*-
"""Acadmics-Custom-YOLOv5

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xtIc7X9CEfMu4HRKFcL_eEWGP3JI4y1Y
"""

from google.colab import drive
drive.mount('/content/drive')

cd /content/drive/MyDrive/Whale/Extract/Try-1

!unzip -q corrected_lbl_85%.zip

cd yolov5

cd Yolo_Sep/

# Commented out IPython magic to ensure Python compatibility.
# clone YOLOv5 repository
!git clone https://github.com/ultralytics/yolov5  # clone repo
# %cd yolov5
!git reset --hard 886f1c03d839575afecb059accf74296fad395b6

# install dependencies as necessary
#!pip install -qr requirements.txt  # install dependencies (ignore errors)
import torch

from IPython.display import Image, clear_output  # to display images
#from utils.google_utils import gdrive_download  # to download models/datasets

# clear_output()
print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))

!pip install install torch==1.11 torchvision==0.12 torchtext==0.12 torchaudio==0.11

!bash /content/drive/MyDrive/Whale/Extract/Try-1/yolov5/weights/download_weights.sh

# Commented out IPython magic to ensure Python compatibility.
# Export code snippet and paste here
# %cd /content
!curl -L "https://app.roboflow.com/ds/NWY1RdmH67?key=vvOVXYl7yu" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip

# Commented out IPython magic to ensure Python compatibility.
# this is the YAML file Roboflow wrote for us that we're loading into this notebook with our data
# %cat ../data.yaml

"""# Define Model Configuration and Architecture

We will write a yaml script that defines the parameters for our model like the number of classes, anchors, and each layer.

You do not need to edit these cells, but you may.
"""

# define number of classes based on YAML
import yaml
with open("data.yaml", 'r') as stream:
    num_classes = str(yaml.safe_load(stream)['nc'])

# Commented out IPython magic to ensure Python compatibility.
#this is the model configuration we will use for our tutorial 
# %cat /content/yolov5/models/yolov5s.yaml

#customize iPython writefile so we can write variables
from IPython.core.magic import register_line_cell_magic

@register_line_cell_magic
def writetemplate(line, cell):
    with open(line, 'w') as f:
        f.write(cell.format(**globals()))

# Commented out IPython magic to ensure Python compatibility.
# %%writetemplate /content/yolov5/models/custom_yolov5s.yaml
# 
# # parameters
# nc: {num_classes}  # number of classes
# depth_multiple: 0.33  # model depth multiple
# width_multiple: 0.50  # layer channel multiple
# 
# # anchors
# anchors:
#   - [10,13, 16,30, 33,23]  # P3/8
#   - [30,61, 62,45, 59,119]  # P4/16
#   - [116,90, 156,198, 373,326]  # P5/32
# 
# # YOLOv5 backbone
# backbone:
#   # [from, number, module, args]
#   [[-1, 1, Focus, [64, 3]],  # 0-P1/2
#    [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4
#    [-1, 3, BottleneckCSP, [128]],
#    [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8
#    [-1, 9, BottleneckCSP, [256]],
#    [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16
#    [-1, 9, BottleneckCSP, [512]],
#    [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32
#    [-1, 1, SPP, [1024, [5, 9, 13]]],
#    [-1, 3, BottleneckCSP, [1024, False]],  # 9
#   ]
# 
# # YOLOv5 head
# head:
#   [[-1, 1, Conv, [512, 1, 1]],
#    [-1, 1, nn.Upsample, [None, 2, 'nearest']],
#    [[-1, 6], 1, Concat, [1]],  # cat backbone P4
#    [-1, 3, BottleneckCSP, [512, False]],  # 13
# 
#    [-1, 1, Conv, [256, 1, 1]],
#    [-1, 1, nn.Upsample, [None, 2, 'nearest']],
#    [[-1, 4], 1, Concat, [1]],  # cat backbone P3
#    [-1, 3, BottleneckCSP, [256, False]],  # 17 (P3/8-small)
# 
#    [-1, 1, Conv, [256, 3, 2]],
#    [[-1, 14], 1, Concat, [1]],  # cat head P4
#    [-1, 3, BottleneckCSP, [512, False]],  # 20 (P4/16-medium)
# 
#    [-1, 1, Conv, [512, 3, 2]],
#    [[-1, 10], 1, Concat, [1]],  # cat head P5
#    [-1, 3, BottleneckCSP, [1024, False]],  # 23 (P5/32-large)
# 
#    [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)
#   ]

# Commented out IPython magic to ensure Python compatibility.
# # train yolov5s on custom data for 100 epochs
# # time its performance
# %%time
# %cd /content/yolov5/
# !python train.py --img 256 --batch 2 --epochs 40 --data './../data.yaml' --cfg ./models/yolov5l.yaml --weights ./yolov5l.pt --name yolov5s_results  --cache

# Commented out IPython magic to ensure Python compatibility.
# # train yolov5s on custom data for 100 epochs
# # time its performance
# %%time
# #%cd /content/yolov5/
# !python3 train.py --img 512 --batch 100 --epochs 50 --data '../data.yaml' --cfg ./models/yolov5s.yaml --weights '' --name yolov5s_results --device 0

# Train YOLOv5s on COCO128 for 3 epochs
!python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights yolov5s.pt --cache

python3 train.py --img 1024 --batch 10 --epochs 50 --data '../data.yaml' --cfg ./models/yolov5x.yaml --weights yolov5x.pt --name yolov5x_results  --device 0

python3 detect.py --weights runs/train/yolov5x_results/weights/best.pt --img 1024 --conf 0.15 --source ../test/images --device 0

python3 train.py --img 1024 --batch 10 --epochs 50 --data '../data.yaml' --cfg ./models/yolov5x.yaml --weights yolov5x6.pt --name yolov5x6_results  --device 0

!python train.py --img 1024 --batch 10 --epochs 50 --data '../data.yaml' --cfg ./models/yolov5s.yaml --weights '/content/Yolo_Sep/yolov5/runs/train/yolov5s_results2/weights/best.pt' --name yolov5s_results  --cache

!python train.py --img 1024 --batch 2 --epochs 50 --data '../data.yaml' --cfg /content/Yolo_Sep/yolov5/runs/train/yolov5s_results2/weights/best.pt --weights '' --name yolov5s_results  --cache

"""# Evaluate Custom YOLOv5 Detector Performance

Training losses and performance metrics are saved to Tensorboard and also to a logfile defined above with the **--name** flag when we train. In our case, we named this `yolov5s_results`. (If given no name, it defaults to `results.txt`.) The results file is plotted as a png after training completes.

Note from Glenn: Partially completed `results.txt` files can be plotted with `from utils.utils import plot_results; plot_results()`.
"""

# Commented out IPython magic to ensure Python compatibility.
# Start tensorboard
# Launch after you have started training
# logs save in the folder "runs"
# %load_ext tensorboard
# %tensorboard --logdir runs

# we can also output some older school graphs if the tensor board isn't working for whatever reason... 
from utils.plots import plot_results  # plot results.txt as results.png
Image(filename='/content/yolov5/runs/train/yolov5s_results/results.png', width=1000)  # view results.png

"""### Curious? Visualize Our Training Data with Labels

After training starts, view `train*.jpg` images to see training images, labels and augmentation effects.

Note a mosaic dataloader is used for training (shown below), a new dataloading concept developed by Glenn Jocher and first featured in [YOLOv4](https://arxiv.org/abs/2004.10934).
"""

# first, display our ground truth data
print("GROUND TRUTH TRAINING DATA:")
Image(filename='/content/yolov5/runs/train/yolov5s_results/test_batch0_labels.jpg', width=900)

# print out an augmented training example
print("GROUND TRUTH AUGMENTED TRAINING DATA:")
Image(filename='/content/yolov5/runs/train/yolov5s_results/train_batch0.jpg', width=900)

"""#Run Inference  With Trained Weights
Run inference with a pretrained checkpoint on contents of `test/images` folder downloaded from Roboflow.
"""

# Commented out IPython magic to ensure Python compatibility.
# trained weights are saved by default in our weights folder
# %ls runs/

# Commented out IPython magic to ensure Python compatibility.
# %ls runs/train/yolov5s_results/weights

# COCO 2017 dataset http://cocodataset.org - first 128 training images
# Train command: python train.py --data coco128.yaml
# Default dataset location is next to /yolov5:
#   /parent_folder
#     /coco128
#     /yolov5



train: /content/train/images  # 128 images
val: /content/valid/images  # 128 images
test: /content/test/images
# number of classes
nc: 1

# class names
names: [ 'Sigmoid']

cd test_img/

!unzip -q Copy\ of\ all_images_1.5k.zip

# Commented out IPython magic to ensure Python compatibility.
# when we ran this, we saw .007 second inference time. That is 140 FPS on a TESLA P100!
# use the best weights!
# %cd /content/yolov5/
!python detect.py --weights runs/train/yolov5s_results2/weights/best.pt --img 1024 --conf 0.05 --source ../test/images

python3 detect.py --weights runs/train/yolov5s_results8/weights/best.pt --img 1024 --conf 0.05 --source ../test/images

#display inference on ALL test images
#this looks much better with longer training above

import glob
from IPython.display import Image, display

for imageName in glob.glob('/content/yolov5/runs/detect/exp3/*.jpg'): #assuming JPG
    display(Image(filename=imageName))
    print("\n")



"""# Export Trained Weights for Future Inference

Now that you have trained your custom detector, you can export the trained weights you have made here for inference on your device elsewhere
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %cp -r /content/Yolo_Sep/yolov5  /content/drive/MyDrive/Yolo_sigmoid/sep/Yolo_Sep/

from google.colab import drive
drive.flush_and_unmount()

!pip install -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt

import torch
import cv2
import torch
from PIL import Image

img =  '031.png'

model = torch.hub.load('ultralytics/yolov5' ,'custom',path = '/content/drive/MyDrive/Yolo/content/yolov5/runs/train/yolov5s_results/weights/best.pt ',force_reload = True)

model.conf = 0.1  # confidence threshold (0-1)
model.iou = 0.1  # NMS IoU threshold (0-1)

model

cd

import os 
import cv2
img = os.path.join('/content/drive/MyDrive/Yolo/test/013.png')

img = cv2.imread(img)

img.shape

img

results = model(img, size = 1024)

results.print()

a = results.pred

print(a)

a[0][1][2]

score = 0
for i in range(len(a)):
  if a[0][i][4]>score:
    score = a[i][0][4]
for i in range(len(a)):
  if score == a[i][0][4]:
    xmin =  int(a[i][0][0])
    ymin =  int(a[i][0][1])
    xmax =  int(a[i][0][2])
    ymax =  int(a[i][0][3])

crop_img = real_img1[ymin:ymax,xmin:xmax]

print(results)

from PIL import Image

Image.fromarray(crop_img)

real_img1 = cv2.imread('/content/0352.png')

!zip -r /content/drive/MyDrive/YOLO1V5Z.zip /content/yolov5/

!unzip "/content/drive/MyDrive/Yolo_sigmoid/YOLO1V5Z.zip" -d "/content/drive/MyDrive/Yolo_sigmoid/"

a[1]

score = 0
for i in range(len(a)):

  
    xmin =  int(a[i][0][0])
    ymin =  int(a[i][0][1])
    xmax =  int(a[i][0][2])
    ymax =  int(a[i][0][3])
    crop_img = real_img1[ymin:ymax,xmin:xmax]
    Image.fromarray(crop_img)
    cv2.imwrite('j'+str(i)+ '.jpg', crop_img)

Image.fromarray(crop_img)

!pip install requirements.txt

cd /content/drive/MyDrive/Yolo_sigmoid/85%accuracy/yolov5-master

# when we ran this, we saw .007 second inference time. That is 140 FPS on a TESLA P100!
# use the best weights!
#%cd /content/drive/MyDrive/Yolo_sigmoid/content/yolov5
!python detect.py --weights /content/drive/MyDrive/Yolo_sigmoid/85%accuracy/yolov5-master/runs/train/yolov5x_results/weights/best.pt --img 1024 --conf 0.05 --source /content/drive/MyDrive/Yolo_sigmoid/85%accuracy/test_img/images --save-txt

python3 detect.py --weights /home/hp-z4/Rakesh/corrected_labelv1/yolov5-master/runs/train/yolov5x_results/weights/best.pt --img 1024 --conf 0.05 --source /home/hp-z4/Rakesh/corrected_labelv1/test_images/images --save-txt

#https://github.com/ultralytics/yolov5/issues/2608

import glob ,os
path_img = glob.glob(os.path.join('/content/drive/MyDrive/Yolo_sigmoid/85%accuracy/test_img/images','*.png'))
path_label = glob.glob(os.path.join('/content/drive/MyDrive/Yolo_sigmoid/85%accuracy/yolov5-master/runs/detect/exp/labels','*.txt'))

len(path_img)

len(path_label)

path_img[500]

path_img.sort()

path_label[500]

import cv2
import matplotlib.pyplot as plt
import os, glob
from tqdm import tqdm
path_img = glob.glob(os.path.join('/content/drive/MyDrive/Yolo_sigmoid/85%accuracy/test_img/images','*.png'))

path_label = glob.glob(os.path.join('/content/drive/MyDrive/Yolo_sigmoid/85%accuracy/yolov5-master/runs/detect/exp/labels','*.txt'))


for i in tqdm(range(len(path_img))):
  img = cv2.imread(path_img[i])
  dh, dw, _ = img.shape

  fl = open(path_label[i], 'r')
  data = fl.readlines()
  fl.close()
  k = 1
  for dt in data:

      # Split string to float
      _, x, y, w, h = map(float, dt.split(' '))

      # Taken from https://github.com/pjreddie/darknet/blob/810d7f797bdb2f021dbe65d2524c2ff6b8ab5c8b/src/image.c#L283-L291
      # via https://stackoverflow.com/questions/44544471/how-to-get-the-coordinates-of-the-bounding-box-in-yolo-object-detection#comment102178409_44592380
      l = int((x - w / 2) * dw)
      r = int((x + w / 2) * dw)
      t = int((y - h / 2) * dh)
      b = int((y + h / 2) * dh)
      
      if l < 0:
          l = 0
      if r > dw - 1:
          r = dw - 1
      if t < 0:
          t = 0
      if b > dh - 1:
          b = dh - 1

      #cv2.rectangle(img, (l, t), (r, b), (0, 0, 255), 1)
      img1 = img[t:b,l:r]
      cv2.imwrite( '/content/drive/MyDrive/Yolo_sigmoid/85%accuracy/test_img/crop_img/' +str(i) + str(k) + '.png' , img1 )
      k = k+1

file1 = open("/content/yolov5/runs/detect/exp2/labels/010.txt","r+")

x = file1.read()

x

arr = []
j = 0
for i in range(len(x)):
  if x[i] == '\n':
    arr.append(x[j:i]) 
    j =i

arr

len(arr)

arr1 = []
for items in arr:
  if items[0]=='0':
    arr1.append(items[1:])
  else :
    arr1.append(items[2:])

arr1

ele = []
for item in arr1:
  k=0
  l = 0
  for j in range(len(item)):
    if item[j] == ' ' and l <4:
      element = (item[k:j])
      k = j+1
      ele.append(element)
      l = l+1
      if l == 4:
        ele.append(item[k:])

while("" in ele) :
    ele.remove("")

len(ele)

ele = [int(float(i)*1024) for i in ele]

len(ele)

ele

import cv2
from google.colab.patches import cv2_imshow
img = cv2.imread('/content/yolov5/runs/detect/exp2/010.png')
path = '/content/yolov5/runs/detect/exp2/cropped/'

img.shape



k= 0
crop = []
from matplotlib import pyplot as plt
for i in range(len(ele)):
  if (i+1)%4 == 0 and i+1>3:
    xmin = ele[i-3]
    ymin = ele[i-2]
    xmax = ele[i-1]
    ymax = ele[i]
    print(xmin,ymin,xmax,ymax)
    k=k+1
    crop_img = img[ymin:ymax,xmin:xmax]
    #plt.imshow(crop_img)
    crop.append(crop_img)
    
   
    #cv2.imwrite( path+ str(k)+ '.jpg', crop_img)

from PIL import Image
Image.fromarray(crop[9])

crop[9]

crop_img

Image.fromarray(img)

with open('/content/yolov5/runs/detect/exp2/labels/010.txt') as f:
    lines = f.readlines()

for items in lines:
  xmin= int(items[1])
  ymin = float(items[2])
  xmax= float(items[3])
  #ymax = int(items[4])

lines

len(ele)